{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nik.luo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, metrics\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97        48\n",
      "          1       0.95      0.95      0.95        39\n",
      "          2       1.00      0.98      0.99        48\n",
      "          3       0.98      0.93      0.95        43\n",
      "          4       1.00      0.95      0.98        42\n",
      "          5       0.96      0.96      0.96        49\n",
      "          6       1.00      0.97      0.99        39\n",
      "          7       0.98      1.00      0.99        49\n",
      "          8       0.89      0.98      0.93        43\n",
      "          9       0.96      0.96      0.96        50\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=4)\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "n_estimators = [100,200,300]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 200, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier()\n",
    "clf_random=RandomizedSearchCV(estimator=clf,param_distributions=random_grid,n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "clf_random.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 60}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9822222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        48\n",
      "          1       0.95      0.97      0.96        39\n",
      "          2       1.00      1.00      1.00        48\n",
      "          3       0.95      0.98      0.97        43\n",
      "          4       1.00      1.00      1.00        42\n",
      "          5       0.98      0.96      0.97        49\n",
      "          6       1.00      0.97      0.99        39\n",
      "          7       1.00      1.00      1.00        49\n",
      "          8       0.98      0.95      0.96        43\n",
      "          9       0.96      0.98      0.97        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = GradientBoostingClassifier(n_estimators=300,min_samples_split=5,min_samples_leaf=4,max_features='sqrt',max_depth=60)\n",
    "clf2.fit(x_train, y_train)\n",
    "y_pred = clf2.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed: 13.2min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "n_estimators = [280,300,320]\n",
    "max_features = ['sqrt']\n",
    "min_samples_split = [4, 5, 6]\n",
    "min_samples_leaf = [3, 4, 5]\n",
    "max_depth=[50,60,70]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "grid_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 60, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 6, 'n_estimators': 280}\n",
      "Acuuracy:  0.9844444444444445\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        48\n",
      "          1       0.95      1.00      0.97        39\n",
      "          2       1.00      1.00      1.00        48\n",
      "          3       0.98      0.95      0.96        43\n",
      "          4       1.00      1.00      1.00        42\n",
      "          5       0.98      0.98      0.98        49\n",
      "          6       1.00      0.97      0.99        39\n",
      "          7       1.00      1.00      1.00        49\n",
      "          8       0.98      0.98      0.98        43\n",
      "          9       0.96      0.96      0.96        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)\n",
    "clf_bestparam = GradientBoostingClassifier(max_depth=grid_result.best_params_['max_depth'],\n",
    "                                           n_estimators=grid_result.best_params_['n_estimators'],\n",
    "                                         max_features=grid_result.best_params_['max_features'],\n",
    "                                         min_samples_split=grid_result.best_params_['min_samples_split'],\n",
    "                                         min_samples_leaf=grid_result.best_params_['min_samples_leaf'])\n",
    "clf_bestparam.fit(x_train,y_train)\n",
    "y_pred=clf_bestparam.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)\n",
    "print (metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
